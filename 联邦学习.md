# 联邦学习

#### 1. new1

* 主要解决：

  * 每次选择一部分客户端，服务器向他们发送全局的参数，在客户端上训练模型，训练出来的参数再发送回服务器。

* 优化：

  * 优化特点

    1. 数据并非IID

    2. 计算成本小，通讯成本大。

       * 每次在客户端上进行更加复杂的运算

       * 每次训练的客户端数目增加，所谓增加并行性

  * 优化方法

    * 使用SGD

    * > 随机梯度下降法(SGD)，许多进展主要是因为模型结构的调整，比如损失函数的优化

#### 2. new2

* 主要解决：
  * 由于行业竞争，隐私保护等原因，数据整合难度大成本高
* 横向学习
* 一些隐私保护方法：
  * SMC：（安全加密计算）每一方除了输入和输出外一无所知。缺点：需要遵循复杂的计算协议，效率不高
  * 差异隐私：差分隐私、k-匿名、多样化方法。通过添加噪声、模糊敏感属性，使第三方难以分辨出个人。缺点：需要在准确性和隐私之间做出权衡。
  * 同态加密：传输参数不传输数据
* 简介信息泄露

  * 随机梯度下降（SGD）等优化算法的参数更新，但没有提供安全保证
* 联邦学习的分类

  * 根据数据在特征和样本 ID 空间中如何在各方之间分配，可分为横向联合学习、纵向联合学习和联合转移学习。
  * <img src="C:\Users\86130\AppData\Roaming\Typora\typora-user-images\image-20240223092717783.png" alt="image-20240223092717783" style="zoom:80%;" />
  * 横向联合学习：
    * 数据集共享相同特征空间，但样本不同的情况下引入的
    * 作者提出了改善通信成本的方法，以促进基于分布在移动客户端上的数据的集中模型的训练。最近，一种名为深度梯度压缩的压缩方法被提出来，以大大降低大规模分布式训练中的通信带宽。

  * 纵向联合学习：
  * 联合迁移学习：





* 摘要

* 正文


### 1. 引言：

> 传统的机器学习的问题（由于行业竞争，隐私保护等原因，数据整合难度大成本高），引出优秀的联邦学习。

许多机器学习算法需要大量的数据，然而，在大多数行业中，数据分散在不同的组织中，以孤岛的形式存在。这使得机器学习技术的实现比我们想象的更加困难。

是否有可能通过跨组织传输数据，将数据融合在一个共同的网站上？事实上，由于隐私安全、行业竞争和复杂的管理程序等原因，在很多情况下，要打破数据源之间的壁垒是非常困难的，甚至是不可能的。这种数据孤岛现象在金融、政府、供应链等多个领域都很常见。

在这种情况下，联邦学习作为一种无需交换用户原始数据的协作学习方式，受到了越来越多的关注，成为一个新的研究热点。

![img](https://1.bp.blogspot.com/-K65Ed68KGXk/WOa9jaRWC6I/AAAAAAAABsM/gglycD_anuQSp-i67fxER1FOlVTulvV2gCLcB/s1600/FederatedLearning_FinalFiles_Flow%2BChart1.png)



* 介绍联邦学习：通俗的语言介绍

联邦学习的工作原理是这样的：客户端从本地的数据中学习来改进当前的共享模型，然后将更改汇总为一个小的重点更新。只有对模型的更新才使用加密通信发送到中心服务器，在那里它会立即与其他用户更新进行平均，以改进共享模型。所有训练数据都保留在客户端，没有单独的更新存储在中心服务器中。

联邦学习提供更智能的模型，更低的延迟和更少的功耗，同时保护用户隐私。这种方法还有另一个直接的好处：除了提供对共享模型的更新外，还可以立即使用客户端上的改进模型，根据拥护使用设备的方式提供个性化的体验。







* 联邦学习的分类：1，2，3

在不同的场景中，客户端之间持有的数据集特征各不相同。假设D_m代表客户端m持有的数据，I表示样本空间ID,Y表示数据集的标签信息，X表示数据集的特征信息，因此，一个完整的训练数据集D应由(I,Y,X)构成。

根据参与训练客户端的数据集特征信息X的不同，联邦学习被分为横向联邦学习、纵向联邦学习和联邦迁移学习[[5](javascript:void(0);)]。

1. 横向联邦学习：

横向联邦学习的特点是数据集特征X和标签信息Y相同，但样本ID不同。例如，两家地 区 性 银行可能在各自地区拥有截然不同的用户群，其用户的交集非常小。但是，它们的业务非常相似，因此特征空间是相同的。

横向联邦学习的公式表达如下。

![](D:\桌面\克盐灶配\WXAQ202105007_03800.jpg)

横向联邦学习如图2所示，u1～u6表示数据集实例

![](D:\桌面\克盐灶配\WXAQ202105007_04000.jpg)







2. 纵向联邦学习：

纵向联邦学习或基于特征的联邦学习（图 2b）适用于两个数据集共享相同的样本 ID 空间但特征空间不同的情况。例如，考虑同一城市的两家不同公司，一家是银行，另一家是电子商务公司。它们的用户集可能包含该地区的大部分居民，因此它们的用户空间的交集很大。但是，由于银行记录的是用户的收支行为和信用等级，而电子商务保留的是用户的浏览和购买记录，因此它们的特征空间截然不同。假设我们希望双方都有一个基于用户和产品信息的产品购买预测模型。纵向联邦学习就是将这些不同的特征聚合起来，以保护隐私的方式计算训练损失和梯度，利用双方的数据协同建立模型。

横向联邦学习的公式表达如下：

`Xi ≠ Xj , Yi ≠ Yj , Ii = Ij ∀Di , Dj , i ≠ j`





3. 联邦迁移学习：

联合迁移学习（FTL）。联邦迁移学习适用于两个数据集不仅在样本上不同，而且在特征空间上也不同的情况。假设有两家机构，一家是位于中国的银行，另一家是位于美国的电子商务公司。由于地理位置的限制，两家机构的用户群体有很小的交集。另一方面，由于业务不同，双方的特征空间只有一小部分重叠。在这种情况下，可以应用迁移学习[3] 技术，为联盟下的整个样本和特征空间提供解决方案（图 2c）。具体来说，利用有限的共同样本集学习两个特征空间之间的共同表示，然后应用于只具有单方特征的样本预测
。FTL 是对现有联合学习系统的重要扩展，因为它能处理的问题超出了现有联合学习算法的范围：

`Xi ≠ Xj , Yi ≠ Yj , Ii ≠ Ij ∀Di , Dj , i ≠ j`





* 联邦学习的架构：

​			本节主要介绍联邦学习的一般架构。值得注意的是，横向和纵向联邦学习系统的架构在设计上有很大不同。

1. 横向联邦学习

横向联合学习系统的典型架构如图 3 所示。在该系统中，具有相同数据结构的 k 个参与者在参数或云服务器的帮助下协作学习一个机器学习模型。这种系统的训练过程通常包括以下四个步骤：

• 步骤 1：参与者在本地计算训练梯度，利用加密[51]、差分隐私[58]或秘密共享[9]技术掩盖部分梯度，并发送掩盖后的梯度。将结果发送到服务器；

• 步骤 2：服务器执行安全聚合，而不了解任何参与者的信息；

• 步骤 3：服务器将汇总结果发回给参与者；

• 步骤 4：参与者利用解密梯度更新各自的模型

![image-20240224104906966](C:\Users\86130\AppData\Roaming\Typora\typora-user-images\image-20240224104906966.png)

> 图三

通过上述步骤不断迭代，直到损失函数收敛，从而完成整个训练过程。这种结构与特定的机器学习算法（逻辑回归、DNN 等）无关，所有参与者将共享最终的模型参数。

2. 纵向联邦学习：

假设 A 公司和 B 公司希望联合训练一个机器学习模型，它们的业务系统各自拥有自己的数据。此外，B 公司也有模型需要预测的标签数据。出于数据隐私和安全考虑，A 和 B 不能直接交换数据。为了确保训练过程中数据的保密性，需要第三方合作者 C 的参与。

联合学习系统由两部分组成，如图 4 所示。

* 第 1 部分.加密实体对齐。由于两家公司的用户组并不相同，系统使用基于加密的用户 ID对齐技术（如 [38, 56] ），在不暴露甲乙双方各自数据的情况下确认双方的共同用户。在实体对齐过程中，系统不会暴露互不重叠的用户。
* 第 2 部分：加密模型训练加密模型训练。确定共同实体后，我们就可以利用这些共同实体的数据来训练机器学习模型。训练过程可分为以下四个步骤（如图 4 所示）：
  * • 步骤 1：合作者 C 创建加密对，将公钥发送给 A 和 B；
  * • 步骤 2：A 和 B 加密并交换梯度和损耗计算的中间结果。
  * • 步骤 3：A 和 B 分别计算加密梯度并添加额外的掩码，B 还计算加密损失；A 和 B 将加密值发送给 C；
  * • 步骤 4：C 解密并将解密后的梯度和损耗发回给 A 和 B；A 和 B消除梯度掩码后，相应地更新模型参数。

![image-20240224105344679](C:\Users\86130\AppData\Roaming\Typora\typora-user-images\image-20240224105344679.png)









* 联邦学习存在的问题，及其解决方案。

自联邦学习的概念提出后，其迅速得到了学术界广泛的关注与研究，但是目前这一研究方向仍有许多威胁与挑战亟待解决，其中，最核心的问题包括通信效率短板明显、隐私安全仍有缺陷、缺乏信任与激励机制，这些问题极大地限制了联邦学习的进一步发展与应用。

#### 3.1 通信效率短板明显

在联邦学习网络中，服务器与远程客户端之间往往需要进行不断的通信来交互模型更新信息，动辄万计的客户端很容易对通信网络造成巨大的带宽负担。通常，全局模型训练时间分为数据处理时间和通信传输时间两部分，而随着计算机设备算力的提升，数据处理时间不断降低，联邦学习的通信传输效率变成限制其训练速度的主要因素[[11](javascript:void(0);)]。

联邦学习与分布式计算的区别是联邦学习的数据集来自各个终端用户，这些用户产生的数据特征往往呈非独立同分布（Non-IID）。Non-IID指的是在概率统计理论中，各数据集中的随机变量不服从同一分布，即对于不同的客户端i和j，它们的数据集概率分布Pi≠Pj。而传统的分布式框架算法只有在处理独立同分布（IID）数据时表现良好，而在处理Non-IID数据时会造成训练过程难以收敛、通信轮数过多等问题[[2](javascript:void(0);),[11](javascript:void(0);)]。另外，在互联网环境中，大量本地模型的更新、上传会导致中心服务器通信开销过大，无法满足正常的应用要求，同时相邻的模型更新中可能包含许多重复更新或者与全局模型不相关的更新[[12](javascript:void(0);)]。

综上，联邦学习的通信效率优化具有重要的研究意义。

#### 3.2 隐私安全仍有缺陷

联邦学习通过源数据不出本地而仅交互模型更新（如梯度信息）的方式来保护用户的敏感数据，开创了数据安全的新范式。理想情况下，联邦学习中客户端通过训练源数据上传本地模型，服务器仅负责聚合和分发每轮迭代形成的全局模型。然而，在真实的网络环境中，模型反演攻击、成员推理攻击、模型推理攻击层出不穷，参与训练的客户端动机难以判断，中心服务器的可信程度难以保证，仅通过模型更新来保护用户隐私的方式显然是不够的。

研究表明，梯度信息会泄露用户的隐私数据[[14](javascript:void(0);),[15](javascript:void(0);),[16](javascript:void(0);),[17](javascript:void(0);),[18](javascript:void(0);),[19](javascript:void(0);),[20](javascript:void(0);)]，攻击者可以通过客户端上传的梯度信息间接推出标签信息和数据集的成员信息。Carlini等[[15](javascript:void(0);)]从训练用户语言数据的递归神经网络中提取出了用户的敏感数据，如特定的银行卡号。Fredrikson等[[16](javascript:void(0);)]研究了如何从模型信息中窃取数据隐私，并通过药量预测实验实现了对线性回归模型的反演攻击，获得了患者的敏感信息。Hitaj等[[18](javascript:void(0);)]用生成对抗网络（GAN）对模型聚合发起攻击，实验结果表明，恶意客户端能够通过产生相似的本地模型更新来窃取用户数据隐私。Gei等[[19](javascript:void(0);)]证明了从梯度信息重建输入数据的可行性与深度网络架构无关，并将一批输入图像用余弦相似度和对抗攻击的方法恢复出来。

#### 3.3 缺乏信任与激励机制

联邦学习为现代社会建立了一个数据安全共享的架构，在未来万物互联的场景中，不同的机构、部门之间的数据联合会形成一个巨大的联邦学习联盟，旨在构建基于大数据和多特征融合的智能分析决策模型。但是，数据联盟需要吸引大量客户端参与到训练过程中，没有高效的激励机制很难吸引足够的训练数据，无法保证最终的智能模型质量；另外，联邦学习并没有针对客户端的信任机制，对于客户端的信誉没有统一的分数评价，这严重影响了对优质客户端的选择，从而导致全局模型精度降低。

### 4 联邦学习技术研究进展

针对联邦学习中存在的威胁与挑战，目前已经存在许多解决方案，本节对大量文献进行总结，分别就联邦学习的通信效率、隐私安全、信任与激励机制3方面展开研究。

目前的研究中针对通信效率的改进主要有以下3种方法。

(1）算法优化：开发适合处理Non-IID和非平衡分布数据的模型训练算法，减少用于传输的模型数据大小，加快模型训练的收敛速度。

(2）压缩：压缩能够有效降低通信数据大小，但对数据的压缩会导致部分信息的丢失，此类方法需要在模型精度和通信效率之间寻找最佳的平衡。

(3）分散训练：将联邦学习框架分层分级，降低中心服务器的通信负担。

在大多数情况下，这几种方法是相辅相成的，通过特定的方法把这几种方案结合是研究的热点方向[[28](javascript:void(0);),[29](javascript:void(0);)]。表1给出现有通信效率算法的性能比较。

#### 4.1.1 算法优化

算法优化是对分布式机器学习框架的改进，使该框架更适用于海量客户端、高频率、低容量、数据特征不均的联邦学习环境，实现通信轮数和模型更新数据的减少。

在分布式计算框架中，客户端每运行一次SGD算法训练，机器学习模型就会向中心服务器上传本轮产生的本地模型更新。但是，频繁的通信交互会对参与训练各方造成不必要的通信负担。

Mc Mahan等[[2](javascript:void(0);)]针对联邦学习的低带宽环境提出Fed Avg算法，要求客户端在本地多次执行SGD算法，然后与中心服务器交互模型更新，实现用更少的通信轮数训练出相同精度的模型。相比于基准算法Fed SGD[[30](javascript:void(0);)]，其在训练不同神经网络的通信轮数上减少了1%～10%，但该算法对于非凸问题没有收敛保证，在非IID数据集上难以收敛[[31](javascript:void(0);)]。

![image-20240224142327408](C:\Users\86130\AppData\Roaming\Typora\typora-user-images\image-20240224142327408.png)

> Fed Avg伪代码

自Fed Avg算法被提出，后续大量研究在此基础上做进一步的拓展，但Fed Avg算法本身有一定的缺陷[[32](javascript:void(0);)]。首先，服务器端聚合时根据客户端数据量大小来分配相应的权重，这导致拥有大量重复数据的客户端能够轻易影响全局模型；其次，客户端仅执行SGD算法和执行固定次数的SGD算法一定限度上限制了模型训练的速度。对此，Li等[[33](javascript:void(0);)]提出Fed Prox算法，根据客户端设备可用的系统资源执行可变次数的SGD算法，缩短收敛时间的同时将模型更新数据压缩了1/2～1/3，更加适用于客户端数据质量、计算资源等联邦学习场景。同样是针对联邦学习框架的改进，Liu等[[34](javascript:void(0);)]认为传统的FL仅利用一阶梯度下降（GD），忽略了对梯度更新的先前迭代，提出了MFL方案，在联邦学习的本地模型更新阶段使用动量梯度下降（MGD），实验证明，在一定条件下该方案显著提升了模型训练的收敛速度。Huang等[[35](javascript:void(0);)]提出迭代自适应的Lo Ada Boost算法，通过分析客户端更新的交叉熵损失，调整本地客户端epoch次数，相对于传统Fed Avg算法固定epoch，准确度与收敛速度均有显著提升。

除了对最初的Fed Avg算法的各种改进以外，在客户端或者服务器上增加筛选算法也是研究方向之一。Wang等[[12](javascript:void(0);)]认为客户端上传的本地模型更新中含有大量的冗余和不相关信息，严重占用通信带宽，因此提出CMFL算法，该算法要求客户端筛选本地模型更新与上一轮全局模型的相关度，通过模型梯度正负符号相同的百分比来避免上传达不到阈值要求的本地模型更新，实现通信开销的降低，但该算法建立在客户端按照协议执行的基础上，系统的鲁棒性较弱。Jiang等[[36](javascript:void(0);)]提出了BACombo算法，利用gossip协议和epsilongreedy算法检查客户端之间随时间变化的平均带宽，最大限度地利用带宽容量，进而加快收敛速度。

#### 4.1.2 压缩

压缩方案通常分为两种：梯度压缩和全局模型压缩。通常情况下，梯度压缩相比于全局模型压缩对通信效率的影响更大，因为互联网环境中上行链路速度比下载链路速度慢得多，交互通信的时间主要集中在梯度数据上传阶段。

横向联邦学习中往往有大量的本地客户端，很难保证每个客户端都拥有稳定可靠的网络连接，低质量的通信会严重降低通信速度。Konečný等[[11](javascript:void(0);)]提出针对本地模型的结构化更新和草图更新算法，客户端被要求在一个低秩或随机掩码后的有限空间中进行模型学习，然后草图更新算法对模型更新进行量化、随机旋转和子采样等压缩操作，该方案被证明在SGD迭代方面显著减慢了收敛速度。在上述基础上，Caldas等[[13](javascript:void(0);)]将该方法应用于对全局模型更新的压缩中，同时提出Federated Dropout思想优化模型更新，中心服务器随机选择全局模型的更小子集并采用量化、随机旋转和子采样等压缩操作，客户端接收到全局模型后解压缩并进行本地模型训练，从而减少了联邦学习对客户端设备资源的影响，允许培训更高容量的模型，并接触到更多样化的用户。Reisizadeh等[[37](javascript:void(0);)]选择将算法优化与压缩的思路结合起来，其提出的Fed PAQ算法要求服务器只选择一小部分客户端参与训练，同时客户端减少上传本地模型次数并在上传之前进行量化更新操作减小通信量。

但是，上述算法采取的都是固定阈值的压缩通信，这种方式在客户端之间模型更新差异较大时显得并不合理。对此，Lu等[[38](javascript:void(0);)]提出自适应阈值梯度压缩算法，客户端通过判断梯度变化，计算得到适当的阈值用于压缩通信，同时保证模型的性能损失较小。

另外，现有的大部分压缩方法只在呈IID分布的客户端数据下表现良好，这些方法并不适合联邦学习场景。对此，Sattler等[[31](javascript:void(0);)]提出一种新的稀疏三元压缩（STC）框架，STC扩展了现有的top-k梯度稀疏化压缩技术，通过Golomb无损编码压缩联邦框架交互的模型更新，使算法更适用于高频率低容量的联邦学习环境，同时保证了在大量客户端参与下的鲁棒性。

#### 4.1.3 分散训练

在联邦学习中，通信拓扑通常是星形拓扑，但这往往会造成中心服务器的通信成本太大，分散拓扑（客户端只与它们的邻居通信）可以作为一种替代方案，如图6所示。在低带宽或高时延网络上运行时，分散拓扑被证明比星形拓扑训练速度更快[[32](javascript:void(0);),[33](javascript:void(0);),[34](javascript:void(0);),[35](javascript:void(0);),[36](javascript:void(0);),[37](javascript:void(0);),[38](javascript:void(0);),[39](javascript:void(0);),[40](javascript:void(0);)]。联邦学习的分散拓扑[[41](javascript:void(0);),[42](javascript:void(0);),[43](javascript:void(0);),[44](javascript:void(0);)]先设定边缘服务器聚合来自客户端设备的本地更新，然后边缘服务器充当客户端的角色与中心服务器交互。例如，Sharma等[[43](javascript:void(0);)]构建了一个多层分布式计算防御框架，通过数据层、边缘层、雾层和云层的协同决策，解决海量数据集中传输的问题。通过这种分层通信的方法可以有效降低中央服务器的通信负担，但它并不适用于所有的场景，因为这种物理层次可能不存在，也不可能预先知道。

#### 4.2 隐私安全

为解决联邦学习中暴露的隐私泄露问题，学术界做了大量研究来增强隐私安全性。根据隐私保护细粒度的不同，联邦学习的隐私安全被分为全局隐私（global privacy）和本地隐私（local privacy），如图7所示。全局隐私假定中心服务器是安全可信任的，即每轮通信的模型更新中心服务器可见。本地隐私假定中心服务器同样可能存在恶意行为，因此本地模型更新在上传到中心服务器之前需要进行加密处理。表2为改进联邦学习隐私安全性的算法对比。

#### 4.2.1 典型隐私保护技术

现有的方案主要通过结合典型隐私保护技术来提供进一步的隐私增强，如差分隐私、安全多方计算、同态加密等技术，这些技术在之前的研究中已经被广泛应用于传统机器学习的隐私保护[[45](javascript:void(0);)]。

定义1差分隐私。设随机化算法A，对于两个至多有一条数据不同的数据集D和D′以及任意可能的输出S，若算法A满足

<img src="https://kns.cnki.net/KXReader/Detail/GetImg?filename=images/WXAQ202105007_09600.jpg&uid=WEEvREcwSlJHSldSdmVpMkl6aHBkSVFwZ21aLy9ON2krd1FQVVZuZVlUdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" alt="正在加载图片" style="zoom:50%;" /> 



则称随机化算法A满足(ε,δ)差分隐私保护。其中，ε代表隐私保护预算，δ是算法允许的误差，通常为较小的常数。

Dwork等[[46](javascript:void(0);)]于2006年提出差分隐私概念，并使用严格的数学推导给出了安全性证明。通常差分隐私算法的噪声机制分为指数噪声、Laplace噪声和高斯噪声，其中，指数噪声主要用于处理离散数据集，Laplace噪声和高斯噪声主要用于处理连续数据集。

定义2安全多方计算[[48](javascript:void(0);)]。假设有n个参与方<img src="https://kns.cnki.net/KXReader/Detail/GetImg?filename=images/WXAQ202105007_40900.jpg&uid=WEEvREcwSlJHSldSdmVpMkl6aHBkSVFwZ21aLy9ON2krd1FQVVZuZVlUdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" alt="img" style="zoom: 50%;" />分别拥有自己的敏感数据<img src="https://kns.cnki.net/KXReader/Detail/GetImg?filename=images/WXAQ202105007_41000.jpg&uid=WEEvREcwSlJHSldSdmVpMkl6aHBkSVFwZ21aLy9ON2krd1FQVVZuZVlUdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" alt="img" style="zoom: 50%;" /><img src="https://kns.cnki.net/KXReader/Detail/GetImg?filename=images/WXAQ202105007_41001.jpg&uid=WEEvREcwSlJHSldSdmVpMkl6aHBkSVFwZ21aLy9ON2krd1FQVVZuZVlUdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" alt="img" style="zoom:50%;" />这n个参与者在不泄露各自输入数据的前提下共同执行一个协议函数<img src="https://kns.cnki.net/KXReader/Detail/GetImg?filename=images/WXAQ202105007_41100.jpg&uid=WEEvREcwSlJHSldSdmVpMkl6aHBkSVFwZ21aLy9ON2krd1FQVVZuZVlUdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" alt="img" style="zoom: 50%;" />

安全多方计算的研究焦点是在没有可信第三方的条件下，参与训练各方安全计算的一个共同的约束函数。姚期智[[49](javascript:void(0);)]于1983年提出安全多方计算的概念，通过混淆电路、不经意传输、秘密分享等技术实现多方共同运算，并确保各方数据的安全性。

定义3同态加密。设有明文数据<img src="https://kns.cnki.net/KXReader/Detail/GetImg?filename=images/WXAQ202105007_41200.jpg&uid=WEEvREcwSlJHSldSdmVpMkl6aHBkSVFwZ21aLy9ON2krd1FQVVZuZVlUdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" alt="img" style="zoom:50%;" /><img src="https://kns.cnki.net/KXReader/Detail/GetImg?filename=images/WXAQ202105007_41201.jpg&uid=WEEvREcwSlJHSldSdmVpMkl6aHBkSVFwZ21aLy9ON2krd1FQVVZuZVlUdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" alt="img" style="zoom:50%;" />这n个数据对应的加密数据为<img src="https://kns.cnki.net/KXReader/Detail/GetImg?filename=images/WXAQ202105007_41300.jpg&uid=WEEvREcwSlJHSldSdmVpMkl6aHBkSVFwZ21aLy9ON2krd1FQVVZuZVlUdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" alt="img" style="zoom:50%;" />若加密算法满足

<img src="https://kns.cnki.net/KXReader/Detail/GetImg?filename=images/WXAQ202105007_10200.jpg&uid=WEEvREcwSlJHSldSdmVpMkl6aHBkSVFwZ21aLy9ON2krd1FQVVZuZVlUdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" alt="正在加载图片" style="zoom:50%;" /> 



则称该加密算法满足同态加密。同态加密能够直接对密文数据进行密码学运算，最终运算结果经解密后与在明文上直接运算结果一致。Rivest等[[50](javascript:void(0);)]于1978年提出同态加密概念。同态加密分为全同态加密和部分同态加密，其中部分同态加密分为乘法同态和加法同态，若一个算法既满足乘法同态又满足加法同态，则称为全同态加密算法。

#### 4.2.2 全局隐私

在全局隐私中，假设存在一个受信任的服务器，外部敌手可能是恶意客户端、分析师、使用学习模型的设备或它们的任何组合。恶意客户端可以从中心服务器接收到它们参与轮的所有模型迭代信息，分析师可以在不同的训练轮中使用不同的超参数来研究模型迭代信息。因此，对中间迭代过程和最终模型进行严格的加密保护十分重要。

在联邦学习进程中，恶意客户端能够通过对分布式模型的分析，获得客户端在训练过程中的贡献及数据集信息。Geyer等[[21](javascript:void(0);)]提出一种针对客户端的差分隐私保护联邦优化算法，实现了对模型训练期间客户端贡献的隐藏，在有足够多客户端参与的情况下，能够以较小的模型性能成本来达到用户级差分隐私。Mc Mahan等[[22](javascript:void(0);)]同样使用差分隐私加密全局模型更新，证明了如果参与联邦学习的客户端数量足够多，对模型更新信息的加密就会以增加计算量为代价而不会降低模型精度。Bhowmick等[[14](javascript:void(0);)]利用差分隐私技术，通过限制潜在对手的能力，提供同等隐私保护程度的同时保证了更好的模型性能。

但是，上述方案中都存在许多影响通信效率和精度的超参数，用户必须谨慎选择才能达到预期效果。Thakkar等[[51](javascript:void(0);)]针对这个缺点提出自适应梯度裁剪策略，对特定层添加不同的噪声，同时对迭代差分隐私机制应用自适应分数剪裁，有效缓解了差分隐私算法中超参数过多的问题。

#### 4.2.3 本地隐私

针对不可信服务器和恶意敌手反演攻击的问题，结合传统的安全多方计算和同态加密等技术，能实现模型信息的无损加解密，但却大大增加了通信成本与计算开销。Bonawitz等[[23](javascript:void(0);)]提出Secure Aggregation模型，结合秘密分享等技术使服务器无法解密单一客户端的梯度信息，仅能执行聚合操作得到全局模型，从而实现对恶意服务器的信息隐藏。Mandal等[[24](javascript:void(0);)]在此工作基础上做了通信效率的改进，引入它非交互式成对密钥交互计算（NIKE）技术，在离线阶段计算主密钥的同时限定用户最多与L个邻居进行掩码操作，从而有效减少了秘密分享的时间开销。Dong等[[28](javascript:void(0);)]将秘密分享与同态加密应用于通信效率算法（Tern Grad），解决了隐私泄露的同时大幅提升了框架的通信和计算开销。Hao等[[52](javascript:void(0);)]通过改进BGV同态加密算法，消除了密钥交换操作并增加了纯文本空间，提供后量子安全性的同时避免了交互密钥导致的通信负担。在纵向联邦学习场景中，各部门进行训练数据对齐时可能造成标签信息和私有数据的泄露。Cheng等[[25](javascript:void(0);)]通过改进XGBoost树模型提出Secure Boost算法，其利用RSA和哈希函数实现各方数据的共有样本ID对齐，同时使用加法同态加密保护各方交互的标签信息和梯度直方图信息，最终实现了与不添加隐私保护的联邦学习相同的模型精度。Aono等[[53](javascript:void(0);)]对深度神经网络模型进行同态加密的思想为联邦学习提供了新方向。

另一个研究热点是联邦学习与差分隐私的融合，由于差分隐私不增加客户端通信成本，被广泛应用于模型更新的隐私保护。学术界的研究主要致力于在保护隐私信息的前提下，尽可能地减少噪声对模型训练的影响，进而提升模型性能。Liu等[[54](javascript:void(0);)]提出一种自适应隐私保护的APFL方案，通过分析数据集的特征向量xi对输出模型的影响，为不同贡献的特征向量分配不同的隐私预算ε，同时减少贡献较少的数据集的噪声，实现严格差分隐私的同时高效保证了全局模型精度与性能。Huang等[[55](javascript:void(0);)]针对客户端之间的不平衡数据提出DP-FL框架，其根据每个用户的数据量设置不同的差分隐私预算ε，设计具有自适应梯度下降算法的差分隐私专用卷积神经网络，来更新每个用户的训练参数，结果证明相较于传统的FL框架，该方案在不平衡数据集中表现较好。Wei等[[56](javascript:void(0);)]将差分隐私与FL的结合做了深入的分析，证明存在最优的K值（1≤K≤总客户端数N），可以在固定的隐私保护级别上实现最佳的收敛性能。Cao等[[29](javascript:void(0);)]则从通信效率和隐私保护的结合出发，结合本地差分隐私，为物联网终端低算力设备提供了资源消耗的隐私保护框架。

但是，上述方案主要致力解决服务器不可信的问题，没有考虑服务器是否正确执行指定聚合操作，恶意服务器很有可能会回传虚假全局模型，蓄意破坏特定客户端对全局模型的使用。针对这类信任问题，Xu等[[57](javascript:void(0);)]提出具有隐私保护和模型可验证的联邦学习框架Verify Net，通过双掩码协议保证客户端本地梯度的保密性，同时将中心服务器欺骗客户端的困难性转移到解NP-hard数学难题上，保证了全局模型的完整性和正确性。

随着联邦学习在移动边缘计算（MEC）和物联网（Io T）中的广泛应用，其存在的安全与隐私问题开始受到关注。Lu等[[58](javascript:void(0);)]提出了一种差分隐私异步联邦学习（DPAFL）方案，通过将本地差分隐私引入联邦学习中，在本地模型的SGD更新中加入高斯噪声以保护隐私性，同时开发了一个新的异步联邦学习架构，它利用分布式的点对点更新方案，而不是集中式更新，以减轻集中式服务器带来的单点安全威胁，更适用于MEC环境。后来，Lu等[[59](javascript:void(0);)]将这种方案应用于车载网络物理系统，解决车辆物联网环境下敏感数据泄露的问题。Hu等[[60](javascript:void(0);)]在异构物联网环境中使用联邦学习结合差分隐私保障用户隐私，提出一种对用户设备异质性具有鲁棒性的FL算法。

#### 4.2.4 模型更新检测

对于模型更新的异常检测同样是确保训练过程安全的重要方式，Fang等[[61](javascript:void(0);)]通过客户端的本地模型发起中毒攻击使全局模型具有较大的测试错误率，并对4种拜占庭鲁棒性联邦学习框架进行了攻击研究，证明了联邦学习对局部模型中毒防御的必要性。

在联邦学习环境中，通常有数以万计的设备参与训练，服务器如果无法及时检测恶意客户端，很容易造成全局模型被污染甚至隐私泄露问题。Li等[[7](javascript:void(0);)]提出基于检测的算法，通过一个预先训练的自动编码器神经网络来检测异常的客户行为，并消除其负面影响，给出各客户端信用评分并拒绝恶意客户端的连接。Zhao[[62](javascript:void(0);)]等通过在服务器端部署GAN，通过客户端模型参数生成审计数据集，并利用该数据集检查参与者模型的准确性，确定是否存在中毒攻击。实验证明，该方法相比传统的模型反演方法，生成的审计数据集质量更高。

但是，上述提出的检测算法需要消耗服务器大量的算力审核客户端本地模型，这导致在全诚实客户端参与的联邦学习中，资源遭到极大的浪费。对此，为减少算力消耗，Kang等[[63](javascript:void(0);)]通过经典的RONI中毒攻击检测算法，比较数据库中有没有相似的本地模型更新效果来判断是否中毒，然后对客户端给出信誉分以供任务发布者选择信誉值高的客户端参与训练，进而排除恶意客户端攻击的可能。Fung等[[64](javascript:void(0);)]将这种比较放在本地模型与上一轮全局模型上，通过比较本地模型更新与全局模型更新向量方向的相似性，判断客户端是否存在恶意。Chen等[[65](javascript:void(0);)]基于受信任的执行环境，设计了训练完整性协议用于检测不诚实的行为，如篡改本地训练模型和延迟本地训练进程，实验证明该方案具有训练完整性与实用性。



#### 4.3 信任与激励机制

联邦学习中，一方面，由于服务器的中心协调地位，往往存在单点故障、执行环境不可信等信任问题；另一方面，如何建立激励机制使参与方自愿消耗算力参与到数据联邦中是一项重大的挑战。鉴于此，学术界主要通过结合区块链技术为联邦学习提供信任与激励机制。区块链具有的数据库不可篡改、安全可验证的特性解决了联邦学习在发展过程中的痛点问题，表3为基于区块链的联邦学习方案对比。

#### 5.1 研究热点

不同于传统的分布式机器学习技术，海量客户端与Non-IID数据集对联邦学习提出了新的挑战。目前，学术界对于联邦学习的研究十分活跃，研究者可能不仅需要掌握机器学习技术，还需要掌握分布式算法优化、密码学、压缩量化、信息论、统计等技术[[80](javascript:void(0);)]。本文介绍了联邦学习在通信效率、隐私安全、信任与激励机制等方向上的研究进展，但仍有一些其他研究方向值得探索。

(1）系统异构。在联邦学习环境中，由于参与训练的客户端之间硬件配置、网络带宽、电池容量等不同，各终端设备的计算能力、通信速度和存储能力各不相同[[81](javascript:void(0);)]。除此之外，联邦学习架构通常会限制终端设备参与训练的数量，尤其是在数百万设备参与的训练中，处于活跃状态的往往只有数百个客户端。每个客户端并不一定可靠，随时可能因为网络故障、算力限制等问题退出现有训练，这些系统级别的异构会给模型整体效能造成极大的挑战。因此，适用于系统异构的联邦学习算法必须满足3点要求：客户端的低参与率；兼容不同的硬件结构；能够容忍训练设备的中途退出。

(2）统计异构。不同的终端设备通常使用各式各样的方式生成、存储和传输数据，因此各设备之间数据的特征和体量可能有很大的不同，导致数据呈Non-IID分布和非平衡分布。尽管这类分布的数据集可以通过通信效率优化的方式处理，但仍然存在一些针对统计异构的解决方法，如通过多任务学习框架学习不同的局部模型[[82](javascript:void(0);)]。类似于元学习，多任务学习由于对个性化和特定于设备建模的支持，已经成为解决数据统计异构性的主流方法。

(3）无线通信。在5G技术日益普及的今天，联邦学习开始被逐渐应用于无线网络领域。由于无线信道的带宽容量有限，因此在发送信息之前，需要对模型更新进行量化压缩，在这种模式下，一个重要的考虑因素是存在量化误差时模型更新的鲁棒性。除了通信带宽外，无线通信中复杂的噪声和干扰也是加剧信道瓶颈的因素[[83](javascript:void(0);)]。因此，开发适用于无线通信的联邦学习算法具有突出的研究意义[[84](javascript:void(0);)]。

除了对联邦学习本身技术的改进，最新的研究进展包括结合边缘计算在物联网领域的应用[[58](javascript:void(0);),[85](javascript:void(0);),[86](javascript:void(0);),[87](javascript:void(0);)]，如图8所示。由于部分终端设备并没有足够的计算资源，同时为了满足智能决策的低时延响应，边缘计算在云中心和边缘设备之间添加了边缘服务器作为中介层，联邦学习作为其“操作系统”满足了智能边缘设备实时决策、多点协同、自主可控的要求。充分利用智能边缘服务器计算、存储、传输能力，改变传统集中上传数据进行决策的方式，破解了传统集中式机器学习数据难以聚合、隐私难以保护、云中心的单点故障等问题，为未来多功能集群、跨多智能设备的实时安全决策提供了可靠的技术保障。

#### 5.2 前景展望

在大数据时代，如何在保障数据安全和隐私的前提下，实现数据共享，促进多源数据的碰撞、融合，最大限度地释放数据价值，成为学术界和产业界面临的挑战之一。而联邦学习作为应对该挑战的一项新兴技术，在诸多领域具有广阔的应用前景。

(1）边缘计算和物联网。随着智能手机和移动互联网的普及应用，大量数据产生在设备的边缘端，移动边缘计算使计算发生在本地设备，而不需要将隐私数据发送到云端。而联邦学习作为边缘计算的操作系统，提供了一种各方协作与共享的协议规范，它能够让边缘设备在不向云端设备发送源数据的情况下，合作训练出一个最优的全局机器学习模型。未来，随着物联网的进一步发展，人工智能和边缘计算将朝着一体化的方向大步向前。

(2）智慧医疗。为了降低人工成本和减少人为操作失误的可能，机器学习技术开始越来越多地应用在医疗领域，用于提升医疗诊治的效率和准确率。但是，由于医疗机构的数据对于隐私和安全的敏感性，医疗数据中心很难收集到足够数量的、特征丰富的、可以全面描述患者症状的数据，而性能良好的机器学习模型往往需要来自多个数据源，包括医疗报告、病例特征、生理指标、基因序列等。联邦迁移学习是解决这类问题的有效方法，无须交换各医疗机构的私有数据，协同所有的训练参与方训练一个共享模型，同时迁移学习技术可以扩展训练数据的样本空间和特征空间，有效降低各医疗机构之间样本分布的差异性。

(3）金融风控。为了维持金融行业稳定、风险控制和防止金融诈骗，银行和金融企业都希望利用人工智能技术为客户提供有效且安全的金融服务。在实际应用中，对客户“肖像”特征的描述通常包括资质信息、购买能力、购买偏好及商品特征等，而这些信息分别分布在银行、电子商务平台和用户的私人社交网络中。出于隐私安全的考虑，将三方数据聚合并不现实，而联邦学习为构建跨企业、跨数据平台以及跨领域的大数据和AI系统提供了良好的技术支持。

(4）智慧城市。随着人工智能、物联网和5G技术的发展，智慧城市的概念已经跃然纸上。然而，在城市的不同信息部门中，如后勤、应急、维稳、安保等，会产生大量的异构数据，形成多个数据孤岛，无法整合利用。联邦学习的异构数据处理能力能够帮助人们创造迅速响应市民需求的智慧城市，解决数据“孤岛”问题，同时基于智慧城市构建的机器学习模型为企业提供个性化服务带来了更多的机遇[[79](javascript:void(0);)]。

(5）涉密数据的安全共享。大数据环境背景下，数据的安全交换显得尤为敏感。常规共享交换使多部门数据汇集的方法，极有可能导致权限难以控制、责任划分不清、问题难以追责，甚至造成失泄密等重大安全事故。如何解决涉密数据的安全共享难题，联邦学习技术的跨域共享特性使各部门之间无须汇集数据即可实现敏感数据的跨域安全共享。

### 6 结束语

本文介绍了联邦学习技术概念、算法原理与分类，并对目前联邦学习中的3个痛点问题的研究进展做出归纳总结，最后展望了联邦学习在各领域的发展前景。随着社会对于隐私安全的日益重视，政府正在逐步加强对私人数据的管控，传统的机器学习模式可能不再符合安全法规。联邦学习作为下一代人工智能大规模协作的基础理论，为目前发展人工智能面临的小数据和隐私等关键问题提供了有效的解决思路。同时，对于联邦学习的国际标准在积极制定中，未来建立在统一标准下的联邦学习必然能够更好地应用于各行各业，发挥更大的效能，进一步推动网络安全的发展[[3](javascript:void(0);)]。
